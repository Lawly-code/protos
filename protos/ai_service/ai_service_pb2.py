# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: protos/ai_service/ai_service.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'protos/ai_service/ai_service.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\"protos/ai_service/ai_service.proto\x12\tassistant\"{\n\x12ImproveTextRequest\x12\x13\n\x0buser_prompt\x18\x01 \x01(\t\x12\x18\n\x0btemperature\x18\x02 \x01(\x02H\x00\x88\x01\x01\x12\x17\n\nmax_tokens\x18\x03 \x01(\x05H\x01\x88\x01\x01\x42\x0e\n\x0c_temperatureB\r\n\x0b_max_tokens\"v\n\rAIChatRequest\x12\x13\n\x0buser_prompt\x18\x01 \x01(\t\x12\x18\n\x0btemperature\x18\x02 \x01(\x02H\x00\x88\x01\x01\x12\x17\n\nmax_tokens\x18\x03 \x01(\x05H\x01\x88\x01\x01\x42\x0e\n\x0c_temperatureB\r\n\x0b_max_tokens\"~\n\x15\x43ustomTemplateRequest\x12\x13\n\x0buser_prompt\x18\x01 \x01(\t\x12\x18\n\x0btemperature\x18\x02 \x01(\x02H\x00\x88\x01\x01\x12\x17\n\nmax_tokens\x18\x03 \x01(\x05H\x01\x88\x01\x01\x42\x0e\n\x0c_temperatureB\r\n\x0b_max_tokens\"h\n\x0cTextResponse\x12\x17\n\x0f\x61ssistant_reply\x18\x01 \x01(\t\x12\x32\n\x08metadata\x18\x02 \x01(\x0b\x32\x1b.assistant.ResponseMetadataH\x00\x88\x01\x01\x42\x0b\n\t_metadata\"I\n\x10ResponseMetadata\x12\x11\n\ttimestamp\x18\x01 \x01(\x03\x12\r\n\x05model\x18\x02 \x01(\t\x12\x13\n\x0btokens_used\x18\x03 \x01(\x05\x32\xde\x01\n\x0b\x41IAssistant\x12\x45\n\x0bImproveText\x12\x1d.assistant.ImproveTextRequest\x1a\x17.assistant.TextResponse\x12;\n\x06\x41IChat\x12\x18.assistant.AIChatRequest\x1a\x17.assistant.TextResponse\x12K\n\x0e\x43ustomTemplate\x12 .assistant.CustomTemplateRequest\x1a\x17.assistant.TextResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'protos.ai_service.ai_service_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_IMPROVETEXTREQUEST']._serialized_start=49
  _globals['_IMPROVETEXTREQUEST']._serialized_end=172
  _globals['_AICHATREQUEST']._serialized_start=174
  _globals['_AICHATREQUEST']._serialized_end=292
  _globals['_CUSTOMTEMPLATEREQUEST']._serialized_start=294
  _globals['_CUSTOMTEMPLATEREQUEST']._serialized_end=420
  _globals['_TEXTRESPONSE']._serialized_start=422
  _globals['_TEXTRESPONSE']._serialized_end=526
  _globals['_RESPONSEMETADATA']._serialized_start=528
  _globals['_RESPONSEMETADATA']._serialized_end=601
  _globals['_AIASSISTANT']._serialized_start=604
  _globals['_AIASSISTANT']._serialized_end=826
# @@protoc_insertion_point(module_scope)
